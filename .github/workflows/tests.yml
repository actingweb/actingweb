name: Tests

on:
  push:
    branches: [ master, main, develop ]
  pull_request:
    branches: [ master, main, develop ]

jobs:
  tests:
    runs-on: ubuntu-latest
    timeout-minutes: 20
    strategy:
      fail-fast: false
      matrix:
        backend: [dynamodb, postgresql]
        python-version: ['3.11']

    name: Tests (Python ${{ matrix.python-version }}, ${{ matrix.backend }})

    services:
      dynamodb:
        image: amazon/dynamodb-local:latest
        ports:
          - 8000:8000

      postgres:
        image: postgres:16-alpine
        env:
          POSTGRES_USER: actingweb
          POSTGRES_PASSWORD: testpassword
          POSTGRES_DB: actingweb_test
        ports:
          - 5432:5432
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: 1.7.0
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v3
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ matrix.backend }}-${{ hashFiles('**/poetry.lock') }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --with dev --extras "all"

      - name: Run PostgreSQL migrations
        if: matrix.backend == 'postgresql'
        run: |
          cd actingweb/db/postgresql
          poetry run alembic upgrade head
        env:
          PG_DB_HOST: localhost
          PG_DB_PORT: 5432
          PG_DB_NAME: actingweb_test
          PG_DB_USER: actingweb
          PG_DB_PASSWORD: testpassword

      - name: Wait for DynamoDB to be ready
        if: matrix.backend == 'dynamodb'
        run: |
          echo "Waiting for DynamoDB to be ready..."
          for i in {1..30}; do
            if curl -s http://localhost:8000/ > /dev/null 2>&1; then
              echo "DynamoDB is ready!"
              exit 0
            fi
            echo "Attempt $i: DynamoDB not ready yet, waiting..."
            sleep 2
          done
          echo "DynamoDB failed to start within 60 seconds"
          exit 1

      - name: Verify xdist groups
        run: |
          echo "Verifying xdist group documentation..."
          poetry run python tests/integration/verify_groups.py

      - name: Run all tests in parallel
        run: |
          echo "Collecting tests..."
          poetry run pytest tests/ --collect-only -q
          echo "Running all tests (unit + integration) with ${{ matrix.backend }} backend..."
          echo "Note: Benchmark tests are excluded from parallel runs (run separately with 'pytest -m benchmark')"
          poetry run pytest tests/ \
            -m "not benchmark" \
            -n 4 \
            --dist loadgroup \
            --max-worker-restart=2 \
            --reruns 2 \
            --reruns-delay 5 \
            -v \
            --tb=short \
            --junitxml=test-results/tests-${{ matrix.backend }}.xml \
            --cov=actingweb \
            --cov-report=xml:coverage-${{ matrix.backend }}.xml \
            --cov-report=html:htmlcov-${{ matrix.backend }}
        env:
          DATABASE_BACKEND: ${{ matrix.backend }}
          # DynamoDB settings
          AWS_ACCESS_KEY_ID: test
          AWS_SECRET_ACCESS_KEY: test
          AWS_DB_HOST: http://localhost:8000
          AWS_DB_PREFIX: test
          # PostgreSQL settings
          PG_DB_HOST: localhost
          PG_DB_PORT: 5432
          PG_DB_NAME: actingweb_test
          PG_DB_USER: actingweb
          PG_DB_PASSWORD: testpassword

      - name: Report test flakiness
        if: always()
        run: |
          echo "Analyzing test results for flakiness..."
          if [ -f test-results/tests-${{ matrix.backend }}.xml ]; then
            # Count retried tests (flaky tests that passed on retry)
            RETRIED=$(grep -o 'rerun=' test-results/tests-${{ matrix.backend }}.xml | wc -l || echo 0)
            echo "Flaky tests (passed on retry): $RETRIED"
            if [ "$RETRIED" -gt 0 ]; then
              echo "‚ö†Ô∏è Warning: Found $RETRIED flaky tests that required retry"
            fi
          fi

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.backend }}
          path: test-results/

      - name: Upload coverage
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-${{ matrix.backend }}
          path: htmlcov-${{ matrix.backend }}/

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v4
        with:
          token: ${{ secrets.CODECOV_TOKEN }}
          files: ./coverage-${{ matrix.backend }}.xml
          flags: ${{ matrix.backend }}
          name: codecov-${{ matrix.backend }}-python-${{ matrix.python-version }}
          fail_ci_if_error: false
          verbose: true

  test-summary:
    runs-on: ubuntu-latest
    needs: tests
    if: always() && github.event_name == 'pull_request'

    steps:
      - name: Download test results
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-*
          path: all-test-results/

      - name: Comment PR with test summary
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');

            // Function to parse JUnit XML and extract test statistics
            function parseJUnitXML(xmlPath) {
              if (!fs.existsSync(xmlPath)) {
                return null;
              }

              const xmlContent = fs.readFileSync(xmlPath, 'utf8');

              // Count total tests
              const testcaseMatches = xmlContent.match(/<testcase/g);
              const totalTests = testcaseMatches ? testcaseMatches.length : 0;

              // Count failures
              const failureMatches = xmlContent.match(/<failure/g);
              const failures = failureMatches ? failureMatches.length : 0;

              // Count errors
              const errorMatches = xmlContent.match(/<error/g);
              const errors = errorMatches ? errorMatches.length : 0;

              // Count flaky tests (tests with rerun attribute)
              const rerunMatches = xmlContent.match(/rerun="/g);
              const flakyTests = rerunMatches ? rerunMatches.length : 0;

              // Count skipped tests
              const skippedMatches = xmlContent.match(/<skipped/g);
              const skipped = skippedMatches ? skippedMatches.length : 0;

              return {
                total: totalTests,
                passed: totalTests - failures - errors - skipped,
                failures: failures,
                errors: errors,
                skipped: skipped,
                flaky: flakyTests
              };
            }

            let comment = '## üß™ Test Results Summary\n\n';
            comment += '### Matrix Testing: Both Database Backends\n\n';
            comment += '| Backend | Tests | Passed | Failed | Flaky | Status |\n';
            comment += '|---------|-------|--------|--------|-------|--------|\n';

            const backends = ['dynamodb', 'postgresql'];
            let hasFlakiness = false;

            for (const backend of backends) {
              const xmlPath = `all-test-results/test-results-${backend}/tests-${backend}.xml`;
              const stats = parseJUnitXML(xmlPath);

              if (stats) {
                const statusEmoji = (stats.failures + stats.errors) > 0 ? '‚ùå' : '‚úÖ';
                const flakyEmoji = stats.flaky > 0 ? '‚ö†Ô∏è' : '‚úÖ';

                comment += `| ${backend} | ${stats.total} | ${stats.passed} | ${stats.failures + stats.errors} | ${stats.flaky} ${flakyEmoji} | ${statusEmoji} |\n`;

                if (stats.flaky > 0) {
                  hasFlakiness = true;
                }
              } else {
                comment += `| ${backend} | - | - | - | - | ‚ö†Ô∏è No results |\n`;
              }
            }

            comment += '\n';

            if (hasFlakiness) {
              comment += '### ‚ö†Ô∏è Flakiness Detected\n\n';
              comment += 'Some tests required retry to pass. This may indicate:\n';
              comment += '- Race conditions in parallel execution\n';
              comment += '- External dependency timeouts\n';
              comment += '- Non-deterministic test behavior\n\n';
              comment += 'Please review the workflow logs for details on which tests were retried.\n\n';
            } else {
              comment += '### ‚úÖ No Flakiness Detected\n\n';
              comment += 'All tests passed on first attempt without requiring retries.\n\n';
            }

            comment += '**Notes**:\n';
            comment += '- Each backend is tested independently with 4 parallel workers\n';
            comment += '- Flaky tests are automatically retried up to 2 times (5 second delay)\n';
            comment += '- Full test results and logs are available in workflow check runs\n';
            comment += '- Coverage reports are uploaded to Codecov with backend-specific flags\n';

            // Post comment
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  type-check:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: 1.7.0
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v3
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --with dev --extras "all"

      - name: Run pyright type checking
        run: poetry run pyright actingweb

      - name: Run ruff linting
        run: poetry run ruff check actingweb tests

  docs:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    name: Documentation Build

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          version: 1.7.0
          virtualenvs-create: true
          virtualenvs-in-project: true

      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v3
        with:
          path: .venv
          key: venv-${{ runner.os }}-docs-${{ hashFiles('**/poetry.lock') }}

      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --with dev --extras "all"

      - name: Build documentation
        run: |
          # Build docs with source in root directory (same as 'make html')
          # -W: treat warnings as errors
          # --keep-going: don't stop on first warning, show all
          # Suppress specific warnings that are pre-existing tech debt:
          # - ref.doc: broken document references (planned docs not yet created)
          # - misc.highlighting_failure: code blocks with special syntax ($$, ...)
          # - duplicate object: autodoc duplicates from multiple includes
          poetry run sphinx-build -W --keep-going \
            -D suppress_warnings="ref.doc,misc.highlighting_failure" \
            -b html . _build/html

      - name: Upload documentation
        uses: actions/upload-artifact@v4
        with:
          name: documentation
          path: _build/html/
